import requests
from dotenv import load_dotenv
from typing import Optional
import os
from loguru import logger
import asyncio
import random
import json


load_dotenv()

async def generate_plan(prompt: str, max_tokens: Optional[int] = 600) -> str:
    logger.info(f"Generating planning for prompt: {prompt} with max tokens: {max_tokens}")

    system_prompt = """You are an intelligent conversational AI with an integrated "research detection engine".
    Your task is to classify queries and produce a structured JSON plan for a deep-search pipeline.
    {
    "main_query": "<the user's full query>",
    "max_tokens": <global token budget>,
    "subqueries": [
        {
        "id": 1,
        "q": "<expanded subquery for LLM reasoning OR a list depending on content>",
        "priority": "high/medium/low",
        "direct_response": true/false,
        "youtube": [
            {"url": "<youtube video URL>"},
            {"full_text": true/false}
        ],
        "document": [
            {"url": "<document URL given by user>"},
            {"query" : "<specific info to extract from the document>"}
        ],
        "time_based_query": "<timezone or null>",
        "max_tokens": <token budget for this subquery>
        }
        ]
    }
        Never output text outside JSON.
        Never include emojis.
        Use at least 2 subqueries for complex questions.
        Document URLs:
        Only include URLs explicitly typed by the user.
        Never infer or create URLs.
        Don't mention youtube urls in queries, just extract them to the youtube field.
        Prioritize direct_response true for simple factual queries.
        Allocate token budgets based on subquery complexity.
        Ensure the final JSON is syntactically correct.
"""

    payload = {
        "model": os.getenv("MODEL"),
        "messages": [
            {
                "role": "system",
                "content": system_prompt.replace("\n", " ").strip()
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.7,
        "stream": False,
        "private": True,
        "referrer": "elixpoart",
        "max_tokens": max_tokens,
        "seed": random.randint(1000, 1000000),
        "frequency_penalty" : 1,
        "logit_bias": {},
        "logprobs": False,
        "modalities" : ["text"]
    }

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {os.getenv('TOKEN')}"
    }

    try:
        response = requests.post(
            "https://enter.pollinations.ai/api/generate/v1/chat/completions",
            headers=headers, json=payload, timeout=30
        )
        if response.status_code != 200:
            raise RuntimeError(f"Request failed: {response.status_code}, {response.text}")

        data = response.json()
        try:
            reply = data["choices"][0]["message"]["content"]
            if "---" in reply and "**Sponsor**" in reply:
                sponsor_start = reply.find("---")
                if sponsor_start != -1:
                    sponsor_section = reply[sponsor_start:]
                    if "**Sponsor**" in sponsor_section:
                        reply = reply[:sponsor_start].strip()
        except Exception as e:
            raise RuntimeError(f"Unexpected response format: {data}") from e

        return reply.strip()

    except requests.exceptions.Timeout:
        logger.warning("Timeout occurred in generate_reply, returning generic system instruction.")
        return f"{prompt}"



if __name__ == "__main__":
    async def main():
        user_prompt = "what's 1+1 and who invented zero, what's the time of kolkata now? and summarize the youtube video https://www.youtube.com/watch?v=dQw4w9WgXcQ and tell me what's in this document url https://www.w3.org/"
        reply = await generate_plan(user_prompt)
        reqID = "test124"
        try:
            reply_json = json.loads(reply)
            os.makedirs(f"searchSessions/{reqID}", exist_ok=True)
            with open(f"searchSessions/{reqID}/{reqID}_planning.json", "w") as f:   
                f.write(json.dumps(reply_json, indent=2))
        except Exception:
            print("Error parsing JSON or writing file.")
        print("\n--- Generated Reply ---\n")
        print(reply)

    asyncio.run(main())